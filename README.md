## ğŸš€ Overview
This project is an **End-to-End Retrieval-Augmented Generation (RAG)** built using **DeepSeek-R1**, **LangChain**, and **Ollama**. It enables users to interact with powerful AI-driven responses in a streamlined and efficient manner.

## ğŸ—ï¸ Tech Stack
- **DeepSeek-R1:1.5B** (LLM Model trained on 1.5 billion parameters)
- **LangChain** (Framework for LLM applications)
- **Ollama** (AI model management)
- **Streamlit** (Frontend UI for interaction)
- **Python** (Backend development)

## ğŸ“ Project Structure
```
Gen-AI-With-DeepSeek
â”‚â”€â”€ venv/               # Virtual environment
â”‚â”€â”€ rag_deep.py         # Main application file
â”‚â”€â”€ requirements.txt    # Python dependencies
â”‚â”€â”€ streamlit/          # Streamlit-based UI components
```
## âš¡ Installation
### 1ï¸âƒ£ Clone the Repository
```sh
git clone https://github.com/krishna25092005/AIDocTalk.git
```
### 2ï¸âƒ£ Create a Virtual Environment
```sh
python -m venv venv
source venv/bin/activate  # Mac/Linux
venv\Scripts\activate     # Windows
```
### 3ï¸âƒ£ Install Dependencies
```sh
pip install -r requirements.txt
```
### 4ï¸âƒ£ Run the Application
```sh
streamlit run rag_deep.py
```
# ğŸ”¥ Features
- âœ… **Real-time AI chat with your document using DeepSeek-R1:1.5B**
- âœ… **Seamless LangChain integration for intelligent processing**
- âœ… **Interactive UI built with Streamlit**
- âœ… **Optimized AI inference using Ollama**
# ğŸ“¸ Screenshots
![Image](https://github.com/user-attachments/assets/b4932d00-f9ba-45cf-ab92-4bc58ce7fe84)

# ğŸ“Œ Future Enhancements
- **Add multi-modal AI capabilities**
- **Improve response caching**
- **Deploy on cloud platforms**
# ğŸ› ï¸ Contributing
**Contributions are welcome! Feel free to fork this repository, make improvements, and create pull requests.**
<h1 align="center">ğŸŒŸ Star this repository if you found it useful! ğŸŒŸ</h1>
