## 🚀 Overview
This project is an **End-to-End Retrieval-Augmented Generation (RAG)** built using **DeepSeek-R1**, **LangChain**, and **Ollama**. It enables users to interact with powerful AI-driven responses in a streamlined and efficient manner.

## 🏗️ Tech Stack
- **DeepSeek-R1:1.5B** (LLM Model trained on 1.5 billion parameters)
- **LangChain** (Framework for LLM applications)
- **Ollama** (AI model management)
- **Streamlit** (Frontend UI for interaction)
- **Python** (Backend development)

## 📁 Project Structure
```
Gen-AI-With-DeepSeek
│── venv/               # Virtual environment
│── rag_deep.py         # Main application file
│── requirements.txt    # Python dependencies
│── streamlit/          # Streamlit-based UI components
```
## ⚡ Installation
### 1️⃣ Clone the Repository
```sh
git clone https://github.com/krishna25092005/AIDocTalk.git
```
### 2️⃣ Create a Virtual Environment
```sh
python -m venv venv
source venv/bin/activate  # Mac/Linux
venv\Scripts\activate     # Windows
```
### 3️⃣ Install Dependencies
```sh
pip install -r requirements.txt
```
### 4️⃣ Run the Application
```sh
streamlit run rag_deep.py
```
# 🔥 Features
- ✅ **Real-time AI chat with your document using DeepSeek-R1:1.5B**
- ✅ **Seamless LangChain integration for intelligent processing**
- ✅ **Interactive UI built with Streamlit**
- ✅ **Optimized AI inference using Ollama**
# 📸 Screenshots
![Image](https://github.com/user-attachments/assets/b4932d00-f9ba-45cf-ab92-4bc58ce7fe84)

# 📌 Future Enhancements
- **Add multi-modal AI capabilities**
- **Improve response caching**
- **Deploy on cloud platforms**
# 🛠️ Contributing
**Contributions are welcome! Feel free to fork this repository, make improvements, and create pull requests.**
<h1 align="center">🌟 Star this repository if you found it useful! 🌟</h1>
